{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["z_1m1PC6tof_","yeCMFQ4yuImU"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Cats on That"],"metadata":{"id":"9zxpP6gHEvij"}},{"cell_type":"markdown","source":["The contents of this notebook constitute the USD MSAAI Image Processing final project Team 5's appendices submission on 12/12/2022.\n","\n","Team 5 consists of the following members:\n","\n","\n","1.   Ian Timmons\n","2.   Ian Feekes\n","3.   Jester Ugalde\n","4.   Yevginiya Okuneva"],"metadata":{"id":"TEswc1I4EzC_"}},{"cell_type":"markdown","source":["## Initial Configuration"],"metadata":{"id":"z_1m1PC6tof_"}},{"cell_type":"markdown","source":["The following few cells perform initial configuration for the notebook, such as importing libraries, setting global variables, and mounting files and repositories as necessary"],"metadata":{"id":"iO8ZBxpCtssh"}},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"yeCMFQ4yuImU"}},{"cell_type":"code","execution_count":27,"metadata":{"id":"E6ppjVl5MfF3","executionInfo":{"status":"ok","timestamp":1670383318021,"user_tz":480,"elapsed":146,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"outputs":[],"source":["import keras\n","import tensorflow as tf\n","from keras.datasets import mnist, cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation, MaxPooling2D, Conv2D, BatchNormalization\n","import matplotlib.pyplot as plt\n","from keras.utils import np_utils\n","from keras.layers import Dense\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import backend as K\n","from PIL import Image, ImageChops, ImageFilter\n","\n","# File operations\n","import os\n","import os.path\n","from pathlib import Path\n","import glob\n","\n","# Image processing and displaying operations\n","import cv2\n","\n","# Dataframe and series operations\n","import pandas as pd\n","import numpy as np\n","\n","# Create callback to limit the number of epochs once learning ceases\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","from keras.utils.vis_utils import plot_model"]},{"cell_type":"markdown","source":["### Global Variables"],"metadata":{"id":"GID76QgV4jsk"}},{"cell_type":"code","source":["# Kaggle Token Path on Google Drive\n","kaggleTokenPath = '/content/drive/My Drive/Colab Notebooks/Image_Processing/kaggle.json'\n","datasetDownloadKaggle = True\n","\n","# Path used for data exploration\n","GeorgianArchitectureImagesPath = '/content/train/arcDataset/Georgian architecture'\n","# Path used to contain data\n","dataDirPath = '/content/train/arcDataset'\n","dataDirPath = '/content/trainarcDataset'"],"metadata":{"id":"FACEHaH14mdn","executionInfo":{"status":"ok","timestamp":1670383320793,"user_tz":480,"elapsed":222,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Mounting Drive"],"metadata":{"id":"rFW1387TuKFK"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iKPgxmIuQaW","executionInfo":{"status":"ok","timestamp":1670383324186,"user_tz":480,"elapsed":868,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"b04ca3c7-62e6-477b-8e19-a51f7b00f1a6"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Configuring & Installing Kaggle"],"metadata":{"id":"si8oUbY4uwDJ"}},{"cell_type":"markdown","source":["To obtain the architecture dataset, it may be stored locally, however it can also be obtained from Kaggle. To run Kaggle download commands to import datasets, one must first install kaggle via CLI."],"metadata":{"id":"xDP3ZI-1u0XN"}},{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"id":"vfwMLGM_ush4","executionInfo":{"status":"ok","timestamp":1670383717879,"user_tz":480,"elapsed":3869,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"31090319-539a-4b76-df40-78ebe702d6c0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.9.24)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"]}]},{"cell_type":"markdown","source":["Now that the CLI is installed for Kaggle, all that is needed is an access token. This can be downloaded from the Kaggle Account page and clicking \"generate API key\" then moving it to a selected part of google drive.\n","\n","https://www.kaggle.com/general/74235"],"metadata":{"id":"WpjswxmJ5vIs"}},{"cell_type":"code","source":["kaggle datasets download -d wwymak/architecture-dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135},"id":"17X8OlFRo388","executionInfo":{"status":"error","timestamp":1670383898030,"user_tz":480,"elapsed":152,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"34ae2514-9c00-47ad-d6dd-b7e842022766"},"execution_count":35,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-d907ce13b2f0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    kaggle datasets download -d wwymak/architecture-dataset\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["!mkdir ~/.kaggle "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjU23doz4-MN","executionInfo":{"status":"ok","timestamp":1670383724147,"user_tz":480,"elapsed":322,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"a09b65d0-01d3-4317-821b-f5b17bf9bf85"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"]}]},{"cell_type":"code","source":["!cp '/content/drive/My Drive/Colab Notebooks/Image_Processing/kaggle.json' ~/.kaggle/"],"metadata":{"id":"I4QUdiOr5ZAf","executionInfo":{"status":"ok","timestamp":1670383742449,"user_tz":480,"elapsed":310,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5dfebba-47e1-4bd8-ad02-9daad5639443"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/My Drive/Image_Processing/kaggle.json': No such file or directory\n"]}]},{"cell_type":"code","source":["!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"9lGcyqZd5oh5","executionInfo":{"status":"ok","timestamp":1670378713281,"user_tz":480,"elapsed":170,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bebc813a-26ae-4c56-b614-3133650b0d15"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"]}]},{"cell_type":"markdown","source":["Download the actual dataset"],"metadata":{"id":"IXG9Fdjn594B"}},{"cell_type":"code","source":["!kaggle datasets download -d wwymak/architecture-dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHcbW4kiuXY7","executionInfo":{"status":"ok","timestamp":1670378713643,"user_tz":480,"elapsed":364,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"a277d514-5dc5-4fd5-9136-17b0f71155e6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.8/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.8/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n","    raise IOError('Could not find {}. Make sure it\\'s located in'\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"]}]},{"cell_type":"markdown","source":["Create training directories and extract the downloaded data into the directories"],"metadata":{"id":"X8q1dZC86fll"}},{"cell_type":"code","source":["!mkdir '/content/train'"],"metadata":{"id":"KwcXJgNR6mW2","executionInfo":{"status":"ok","timestamp":1670378713816,"user_tz":480,"elapsed":176,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#!unzip train.zip -d train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNEa5XmuX4Js","executionInfo":{"status":"ok","timestamp":1670379446499,"user_tz":480,"elapsed":218,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"2fcb9d73-6e03-4b85-d16a-90ffaccd1a7e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open train.zip, train.zip.zip or train.zip.ZIP.\n"]}]},{"cell_type":"code","source":["!unzip /root/.kaggle/architecture-dataset -d /content/train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_qVBTfE6vhk","executionInfo":{"status":"ok","timestamp":1670379474134,"user_tz":480,"elapsed":315,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"88eb6142-0a8c-41e2-9a92-b61c72fb9826"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open /root/.kaggle/architecture-dataset, /root/.kaggle/architecture-dataset.zip or /root/.kaggle/architecture-dataset.ZIP.\n"]}]},{"cell_type":"markdown","source":["## EDA and Pre-Processing"],"metadata":{"id":"ZBH1WRV-SqW3"}},{"cell_type":"markdown","source":["Include a clear discussion that ensures all steps are clearly explained and addresses the following:\n","How did you make sure that you are ready to apply deep learning models?\n","What type of pre-processing is required on your data?\n","How can you define and refine various feature variables that you may potentially use for the modeling?\n","Have additional features added to demonstrate necessary image processing, image preparation, or image access for later AI computation?\n"],"metadata":{"id":"OcYd-DS5SokA"}},{"cell_type":"code","source":["# List of file/directory names which do not have data of interest\n","# These files describe architectural relationships and time frames, which are\n","#    not currently relevant to our application\n","badSubDirNames = ['ReadMe~', 'ReadMe', 'arcRelationship25.txt', 'arcNames25.txt',\n","                  'relationship.txt']\n","\n","# Get all files in our data directory\n","subDirNames = os.listdir(dataDirPath)\n","\n","for name in badSubDirNames:\n","  subDirNames.remove(name)\n","  assert(name not in subDirNames)\n","\n","subDirNames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"tLhp_BNrmD2x","executionInfo":{"status":"error","timestamp":1670378714477,"user_tz":480,"elapsed":663,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"outputId":"26181204-6a92-4c02-91e2-fbcd4a0b9866"},"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-72820f16a281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get all files in our data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msubDirNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataDirPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbadSubDirNames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/trainarcDataset'"]}]},{"cell_type":"code","source":["# Declare Empty data frame object\n","MAIN_ARC = pd.DataFrame(dtype = str)\n","\n","# Go through each directory and pick up all jpg files, appending the directory name as a column to the data frame\n","for directoryName in subDirNames:\n","  fullPath = dataDirPath + \"/\" + directoryName\n","  # Load files from the dataset\n","  fileList = list(Path(fullPath).glob(r\"*.jpg\"))\n","  # Convert list of file names into a series\n","  fileImageSeries = pd.Series(fileList, name=\"directoryName\").astype(str)\n","  MAIN_ARC[directoryName] = fileImageSeries\n","\n","# Data frame should have a column for each directory and should have many columns\n","assert(MAIN_ARC.shape[0] > 0 and MAIN_ARC.shape[1] == len(subDirNames))\n","\n","# Show the first 5 columns of our new data frame object\n","MAIN_ARC.head(5)"],"metadata":{"id":"3sFnrefFn4uk","executionInfo":{"status":"error","timestamp":1670380037569,"user_tz":480,"elapsed":143,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}},"colab":{"base_uri":"https://localhost:8080/","height":244},"outputId":"45f604e8-e483-45bf-e619-9bcc130b05dd"},"execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-b46e4f8dd527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Go through each directory and pick up all jpg files, appending the directory name as a column to the data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectoryName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubDirNames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mfullPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDirPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirectoryName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Load files from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'subDirNames' is not defined"]}]},{"cell_type":"code","source":["numColumns = 0\n","for col in MAIN_ARC.columns:\n","  numColumns = numColumns + len(col)\n","\n","print(numColumns)"],"metadata":{"id":"DjzDskpUtnY6","executionInfo":{"status":"aborted","timestamp":1670378714479,"user_tz":480,"elapsed":8,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dropping bad entries"],"metadata":{"id":"xjBB-TI4xzd6"}},{"cell_type":"markdown","source":["We can see from the following cell that the images are not all of equal dimensions and will need to be resized and normalized"],"metadata":{"id":"C_58UKT7IBs7"}},{"cell_type":"code","source":["# Declare lists to illustrate the different widths and heights in the images\n","differentWidths = []\n","differentHeights = []\n","\n","figure,axis = plt.subplots(3,3,figsize=(14,14))\n","\n","for i_ind,i_ops in enumerate(axis.flat):\n","    # Process current frame as opencv structure and convert the proper color format\n","    IMAGE_READING = cv2.cvtColor(cv2.imread(MAIN_ARC[MAIN_ARC.columns[2]][i_ind]),cv2.COLOR_BGR2RGB)\n","    # Append dimensions to the array list for data analysis - all images should be rgb\n","    if IMAGE_READING.shape[0] not in differentHeights:\n","      differentHeights.append(IMAGE_READING.shape[0])\n","    if IMAGE_READING.shape[1] not in differentWidths:\n","      differentWidths.append(IMAGE_READING.shape[1])\n","    i_ops.axis(\"off\")\n","    i_ops.imshow(IMAGE_READING)\n","    \n","plt.tight_layout()\n","plt.show()    \n","\n","# Show that the images have different dimensions and will need to be resized\n","print()\n","print(\"The number of different widths for the first 9 images is:\", len(differentWidths))\n","print(\"The number of different heights for the first 9 images is:\", len(differentHeights))"],"metadata":{"id":"F94dKPAkHfxP","executionInfo":{"status":"aborted","timestamp":1670378714479,"user_tz":480,"elapsed":8,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Declare a variable to be the smallest image shape\n","smallestImageShape = cv2.imread(MAIN_ARC[MAIN_ARC.columns[1]][0]).shape\n","# Get the width and height\n","smallestX = smallestImageShape[0]\n","smallestY = smallestImageShape[1]\n","# Iterate through data frame and determine the largest possible resolution we can resize to\n","for col in MAIN_ARC.columns:\n","  for row in MAIN_ARC[col]:\n","    # Data frame organization will break for directories of differing numbers of files\n","    if row != 'nan' and type(row) == str:\n","      image = cv2.imread(row)\n","      if image.shape[0] < smallestX:\n","        smallestX = image.shape[0]\n","      if image.shape[1] < smallestY:\n","        smallestY = image.shape[1]\n","\n","smallestImageShape = (smallestX, smallestY)\n","smallestImageShape"],"metadata":{"id":"JAh6z9JzvsGh","executionInfo":{"status":"aborted","timestamp":1670378714480,"user_tz":480,"elapsed":8,"user":{"displayName":"Ian Timmons","userId":"05388098149476696383"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modeling Methods, Validation, and Performance Metrics"],"metadata":{"id":"iOTBOtGmSu8M"}},{"cell_type":"markdown","source":["Perform modeling using the training dataset.\n","Evaluate the model(s) using the test dataset and validate as well.\n","Ensure all modeling methods are well-motivated, correctly implemented, and, to the extent appropriate, span the range of methods discussed in this course.\n","Cross-validation and/or held-out test sets are used in accordance with best practices to assess model performance.\n","Performance metrics are carefully tailored to the project objectives.\n"],"metadata":{"id":"pU-q1vJdSuB0"}},{"cell_type":"markdown","source":["## Modeling Results and Findings"],"metadata":{"id":"FxViJWT_S28X"}},{"cell_type":"markdown","source":["Discuss the results comparing different models and explain the differences and the challenges.\n","Ensure all project objectives are fully met, findings are clearly presented, and question(s) are technically addressed in the report.\n","Include tables/graphs comparing the different models, including their characteristics, performance, and accuracy."],"metadata":{"id":"ZyAy5eMJS2Pq"}}]}